 * extend arc.c to allow the fetch routine to instruct the cache subsystem on whether to cache
   the retrieved object or discard it after dowloading

 * weight items distinguishing between not owned (but fetched from a peer) and owned to decide 
   if the value needs to be cached or not. 
   The idea is that not-owned items would be cached locally only if 'hot'. 
   For the strategy to use it might be worth to look at how groupcache does 
   or use a Count-Min Sketch based approach

 * support replicas

 * support message compression

 * extend the protocol to support get_multi and set_multi messages.
   This will allow clients without knowledge of the complete shard (or always communicating
   with a single node) to still commence set_multi/get_multi commands letting the server
   to take care of parallelizing the operation if possible.

 * server-side get_multi() and set_multi() implementation, as for the client implementation
   server nodes can take care of parallelizing (when possible) batch set/get commands which involve
   keys not owned by the current server.

 * extend the expire interface in set() commands to allow the use of some flag to 
   control if the expiry time should be renewed when the key is accessed or not
   (and let it honor the initial expiration time)

 * parallelize eviction
   evict commands are very small and can be handled quickly but now it's
   only one thread making this job and it might be not enough in case of
   a big number of delete requests for keys not owned by the
   receiving instance)

 * parallelize migrations

 * refactor arc.c to get rid of the recursive lock
   the fetch logic should be taken out of arc_move() and moved to a separated function
   which can then be used also in arc_lookup() when a new object is being created because a new
   key was requested and it wasn't in the cache.
   arc_lookup must try immediately to fetch the key/value from the storage to check 
   if it exists or not ... so that it can fail early without adding a new empty object
   to the hashtable to then fail later at arc_move() when trying to fetch the value.
   The problem with such a change will be finding a way to keep fetching of the object serialized
   so that multiple threads won't try accessing the storage to fetch the same object.
   At the moment this is ensured by locking the actual object (which is inserted immediately
   when a new key is requested , so further threads will lock on that same object).
   If this won't be the case anymore we still need a way to serialize access to the
   storage for the same key, while still allowing parallel access to different keys


