 * in serving.c unregister the output handler (shardcache_output_handler()) if there is
   no pending output and register the callback instead when new data is being added to
   the output buffer. This might be beneficial for performances in case of a big number
   of client connections because we would stop wasting time calling the output callback
   for each active connection while most of them don't have any output ready.

 * minimize the usage of the NOOP to verify the connection status.
   When connections are reused quickly there is no point in checking the status again,
   so a threshold should be added which controls whether we need to check the status
   or we can avoid since it has been just used

 * refactor the API actually exposed to set internal shardcache flags and options
   once an instance has been created. The way it's actually implemented is suboptimal
   because adding a new option requires to add both a member to the shardcache_t structure
   and a new function exposed by the shardcache library. Since options and flags are growing
   and there will be probably more in the future, there is already the need of a proper
   API to allow getting/setting internal flags and params and a better way of storing
   those within the shardcache_t structure

 * complete and test the replica support

 * support message compression

 * extend the protocol to support get_multi and set_multi messages.
   This will allow clients without knowledge of the complete shard (or always communicating
   with a single node) to still commence set_multi/get_multi commands letting the server
   to take care of parallelizing the operation if possible.

 * server-side get_multi() and set_multi() implementation, as for the client implementation
   server nodes can take care of parallelizing (when possible) batch set/get commands which involve
   keys not owned by the current server.

 * extend the expire interface in set() commands to allow the use of some flag to 
   control if the expiry time should be renewed when the key is accessed or not
   (and let it honor the initial expiration time).

 * parallelize migrations

 * refactor arc.c to get rid of the recursive lock
   the fetch logic should be taken out of arc_move() and moved to a separated function
   which can then be used also in arc_lookup() when a new object is being created because a new
   key was requested and it wasn't in the cache.
   arc_lookup must try immediately to fetch the key/value from the storage to check 
   if it exists or not ... so that it can fail early without adding a new empty object
   to the hashtable to then fail later at arc_move() when trying to fetch the value.
   The problem with such a change will be finding a way to keep fetching of the object serialized
   so that multiple threads won't try accessing the storage to fetch the same object.
   At the moment this is ensured by locking the actual object (which is inserted immediately
   when a new key is requested , so further threads will lock on that same object).
   If this won't be the case anymore we still need a way to serialize access to the
   storage for the same key, while still allowing parallel access to different keys.

* weight items distinguishing between not owned (but fetched from a peer) and owned to decide 
   if the value needs to be cached or not. 
   At the moment a simple/dumb logic is implemented which basically keep the remote items only
   10% of times (by calling  rand() % 10). Better approaches are possible but it's still unclear
   if they are worth implementing or not.

 * parallelize eviction
   evict commands are very small and can be handled quickly but now it's
   only one thread making this job and it might be not enough in case of
   a big number of delete requests for keys not owned by the
   receiving instance).

